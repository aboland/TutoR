---
title: "GDPR Fines"
author: "Aidan Boland"
date: "4/23/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, error = F)
library(dplyr)
library(ggplot2)
```

## Read Data

*Note taat these files are tab deliminated (tsv) rather than comma (csv).

```{r read in}
gdpr_violations <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-21/gdpr_violations.tsv')
gdpr_text <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-21/gdpr_text.tsv')
```


### Check out Data

```{r view}
head(gdpr_violations)
head(gdpr_text)
```


First dataset has info on country and fine amount, ther second has text regarding the fine.


# Fine amounts

```{r}

gdpr_violations %>%
  ggplot(aes(date, price)) +
  geom_point()


gdpr_violations %>%
  ggplot(aes(date, price, colour = type)) +
  geom_point()

gdpr_violations %>%
  select(type) %>%
  distinct()

gdpr_violations %>%
  select(type) %>%
  distinct() %>%
  arrange(type)

gdpr_violations %>%
  ggplot(aes(date, price, colour = name)) +
  geom_point()


gdpr_violations %>%
  ggplot(aes(x = name, y = price, colour = name)) +
  geom_point()

gdpr_violations %>%
  ggplot(aes(x = name, y = price, colour = name)) +
  geom_point() +
  coord_flip()

gdpr_violations %>%
  ggplot(aes(x = name, y = price, colour = name)) +
  geom_point() +
  coord_flip() +
  theme(legend.position = 'none')

gdpr_violations %>%
  ggplot(aes(x = name, y = price, colour = name)) +
  geom_jitter() +
  coord_flip() +
  theme(legend.position = 'none')


library(scales)

gdpr_violations %>%
  ggplot(aes(x = name, y = price, colour = name)) +
  geom_point() +
  coord_flip() +
  theme(legend.position = 'none') +
  scale_y_continuous(label = comma_format(prefix = "€")) # label_dollar

gdpr_violations %>%
  ggplot(aes(x = name, y = price, colour = name)) +
  geom_point() +
  coord_flip() +
  theme(legend.position = 'none') +
  scale_y_continuous(label = dollar_format(prefix = "€", scale = 1000000)) # label_dollar

gdpr_violations %>%
  ggplot(aes(x = name, y = price, colour = name)) +
  geom_point() +
  coord_flip() +
  theme(legend.position = 'none') +
  scale_y_continuous(label = dollar_format(prefix = "€", scale = 0.000001)) # label_dollar

gdpr_violations %>%
  ggplot(aes(x = name, y = price, colour = name)) +
  geom_point() +
  coord_flip() +
  theme(legend.position = 'none') +
  scale_y_continuous(label = dollar_format(prefix = "€", scale = 0.000001)) + # label_dollar
  labs(y = "Price (Millions)", x = "", title = "GDPR Fines by Country")
```



```{r find_outlier}

gdpr_violations %>%
  filter(price > 40000000)


gdpr_violations %>%
  group_by(controller) %>%
  summarise(total_fines = sum(price)) %>%
  arrange(desc(total_fines)) %>%
  head(10)

gdpr_violations %>%
  group_by(controller) %>%
  summarise(total_fines = sum(price), number_of_fines = length(price)) %>%
  arrange(desc(total_fines)) %>%
  head(10)
```



# Text Analysis


```{r}
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")




 # document_term_matrix (DTM)
my_dtm_func <- function(data_in){

  docs <- Corpus(VectorSource(data_in))
  # inspect(docs)
  
  toSpace <- content_transformer(function(x , pattern ) gsub(pattern, " ", x))
  docs <- tm_map(docs, toSpace, "/")
  docs <- tm_map(docs, toSpace, "@")
  docs <- tm_map(docs, toSpace, "\\|")
  docs <- tm_map(docs, toSpace, "–")
  
  docs <- tm_map(docs, toSpace, "’")
  
  # Convert the text to lower case
  docs <- tm_map(docs, content_transformer(tolower))
  # Remove numbers
  docs <- tm_map(docs, removeNumbers)
  # Remove english common stopwords
  docs <- tm_map(docs, removeWords, stopwords("english"))
  # Remove your own stop word
  # specify your stopwords as a character vector
  docs <- tm_map(docs, removeWords, c("and", "etc")) 
  # Remove punctuations
  docs <- tm_map(docs, removePunctuation)
  # Eliminate extra white spaces
  docs <- tm_map(docs, stripWhitespace)
  
  
  dtm <- TermDocumentMatrix(docs)
  m <- as.matrix(dtm)
  v <- sort(rowSums(m),decreasing = TRUE)
  d <- data.frame(word = names(v),freq = v)
  # head(d, 10)
  return(d)
}





gdpr_summary <- my_dtm_func(gdpr_violations$summary)

wordcloud(words = gdpr_summary$word, 
          freq = gdpr_summary$freq, 
          min.freq = 1,
          max.words = 200, 
          random.order = FALSE, 
          rot.per = 0.35, 
          colors = brewer.pal(8, "Dark2"))

```

```{r}


gdpr_full <- my_dtm_func(gdpr_text)

wordcloud(words = gdpr_full$word, 
          freq = gdpr_full$freq, 
          min.freq = 1,
          max.words = 200, 
          random.order = FALSE, 
          rot.per = 0.35, 
          colors = brewer.pal(8, "Dark2"))




```



```{r}

my_dtm_func2 <- function(data_in, my_stopwords){

  docs <- Corpus(VectorSource(data_in))
  # inspect(docs)
  
  toSpace <- content_transformer(function(x , pattern ) gsub(pattern, " ", x))
  docs <- tm_map(docs, toSpace, "/")
  docs <- tm_map(docs, toSpace, "@")
  docs <- tm_map(docs, toSpace, "\\|")
  docs <- tm_map(docs, toSpace, "–")
  
  docs <- tm_map(docs, toSpace, "’")
  
  # Convert the text to lower case
  docs <- tm_map(docs, content_transformer(tolower))
  # Remove numbers
  docs <- tm_map(docs, removeNumbers)
  # Remove english common stopwords
  docs <- tm_map(docs, removeWords, stopwords("english"))
  # Remove punctuations
  docs <- tm_map(docs, removePunctuation)
  # Eliminate extra white spaces
  docs <- tm_map(docs, stripWhitespace)
  
  # Remove your own stop word
  # specify your stopwords as a character vector
  docs <- tm_map(docs, removeWords, my_stopwords) 
  
  dtm <- TermDocumentMatrix(docs)
  m <- as.matrix(dtm)
  v <- sort(rowSums(m),decreasing = TRUE)
  d <- data.frame(word = names(v),freq = v)
  # head(d, 10)
  return(d)
}







gdpr_full <- my_dtm_func2(gdpr_text, c("http", "gdprinfoeu", "artgdpr"))

wordcloud(words = gdpr_full$word, 
          freq = gdpr_full$freq, 
          min.freq = 1,
          max.words = 200, 
          random.order = FALSE, 
          rot.per = 0.35, 
          colors = brewer.pal(8, "Dark2"))



gdpr_full <- my_dtm_func2(gdpr_text, c("http", "gdpr-info.eu", "art-1-gdpr"))

wordcloud(words = gdpr_full$word, 
          freq = gdpr_full$freq, 
          min.freq = 1,
          max.words = 200, 
          random.order = FALSE, 
          rot.per = 0.35, 
          colors = brewer.pal(8, "Dark2"))

```